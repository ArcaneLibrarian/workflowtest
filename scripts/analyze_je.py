#!/usr/bin/env python3
import argparse
import json
from pathlib import Path

import pandas as pd


def detect_date_range(series: pd.Series) -> dict | None:
    if series.empty:
        return None
    if pd.api.types.is_datetime64_any_dtype(series):
        parsed = series
    else:
        parsed = pd.to_datetime(series, errors="coerce", infer_datetime_format=True)
    non_null = parsed.notna().sum()
    if non_null == 0:
        return None
    ratio = non_null / len(series)
    if ratio < 0.5:
        return None
    return {
        "non_null": int(non_null),
        "min": parsed.min().isoformat() if non_null else None,
        "max": parsed.max().isoformat() if non_null else None,
    }


def numeric_summary(series: pd.Series) -> dict | None:
    if not pd.api.types.is_numeric_dtype(series):
        return None
    non_null = series.notna().sum()
    if non_null == 0:
        return None
    return {
        "non_null": int(non_null),
        "mean": float(series.mean()),
        "min": float(series.min()),
        "max": float(series.max()),
        "sum": float(series.sum()),
    }


def build_summary(excel_path: Path, output_dir: Path) -> None:
    output_dir.mkdir(parents=True, exist_ok=True)
    workbook = pd.ExcelFile(excel_path)

    summary = {
        "workbook": excel_path.name,
        "sheet_count": len(workbook.sheet_names),
        "sheets": [],
    }

    column_rows = []

    for sheet_name in workbook.sheet_names:
        df = workbook.parse(sheet_name)
        sheet_summary = {
            "sheet": sheet_name,
            "row_count": int(df.shape[0]),
            "column_count": int(df.shape[1]),
            "columns": list(df.columns.astype(str)),
            "date_ranges": {},
            "numeric_summaries": {},
        }

        for column in df.columns:
            series = df[column]
            column_rows.append(
                {
                    "sheet": sheet_name,
                    "column": str(column),
                    "dtype": str(series.dtype),
                    "non_null": int(series.notna().sum()),
                    "nulls": int(series.isna().sum()),
                    "unique": int(series.nunique(dropna=True)),
                }
            )

            date_info = detect_date_range(series)
            if date_info:
                sheet_summary["date_ranges"][str(column)] = date_info

            numeric_info = numeric_summary(series)
            if numeric_info:
                sheet_summary["numeric_summaries"][str(column)] = numeric_info

        summary["sheets"].append(sheet_summary)

        describe_path = output_dir / f"describe_{sheet_name}.csv"
        df.describe(include="all").to_csv(describe_path)

    (output_dir / "column_stats.csv").write_text(
        pd.DataFrame(column_rows).to_csv(index=False)
    )

    summary_path = output_dir / "summary.json"
    summary_path.write_text(json.dumps(summary, indent=2))

    md_lines = [
        f"# Journal Entry Summary for `{excel_path.name}`",
        "",
        f"Total sheets: **{summary['sheet_count']}**",
        "",
    ]
    for sheet in summary["sheets"]:
        md_lines.extend(
            [
                f"## Sheet: {sheet['sheet']}",
                f"- Rows: **{sheet['row_count']}**",
                f"- Columns: **{sheet['column_count']}**",
            ]
        )
        if sheet["date_ranges"]:
            md_lines.append("- Date ranges:")
            for col, info in sheet["date_ranges"].items():
                md_lines.append(
                    f"  - {col}: {info['min']} â†’ {info['max']} (non-null {info['non_null']})"
                )
        if sheet["numeric_summaries"]:
            md_lines.append("- Numeric summaries:")
            for col, info in sheet["numeric_summaries"].items():
                md_lines.append(
                    "  - {col}: mean {mean:.2f}, min {min:.2f}, max {max:.2f}, sum {sum:.2f}".format(
                        col=col,
                        mean=info["mean"],
                        min=info["min"],
                        max=info["max"],
                        sum=info["sum"],
                    )
                )
        md_lines.append("")

    (output_dir / "summary.md").write_text("\n".join(md_lines))

    index_lines = [
        "# Output Files",
        "",
        "This folder is generated by the journal entry analysis workflow.",
        "",
        "- `summary.json`: machine-readable summary",
        "- `summary.md`: human-readable summary",
        "- `column_stats.csv`: per-column statistics",
        "- `describe_<sheet>.csv`: pandas describe output per sheet",
    ]
    (output_dir / "index.md").write_text("\n".join(index_lines))


def main() -> None:
    parser = argparse.ArgumentParser(description="Analyze journal entry Excel data.")
    parser.add_argument(
        "--input",
        type=Path,
        default=Path("je_samples (1).xlsx"),
        help="Path to the Excel workbook",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("outputs"),
        help="Directory to write outputs",
    )
    args = parser.parse_args()

    if not args.input.exists():
        raise SystemExit(f"Input file not found: {args.input}")

    build_summary(args.input, args.output)


if __name__ == "__main__":
    main()
